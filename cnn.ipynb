{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# blurred_img = cv2.GaussianBlur(labeled_img, (5,5), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_img(name):\n",
    "    labeled_img = cv.imread('D:/ML work/NOAA Sea Lion count/Data/Semantics Segmentation/' + name + '-processed.tif')\n",
    "    original_img = cv.imread('D:/ML work/NOAA Sea Lion count/Data/Train/' + name + '.jpg')\n",
    "    \n",
    "    return original_img, labeled_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reference: https://github.com/sjchoi86/Tensorflow-101/blob/master/notebooks/semseg_basic.ipynb\n",
    "def unpooling(inputOrg, size, mask=None):\n",
    "    # m, c, h, w order\n",
    "    m = size[0]\n",
    "    h = size[1]\n",
    "    w = size[2]\n",
    "    c = size[3]\n",
    "    input = tf.transpose(inputOrg, [0, 3, 1, 2])\n",
    "    x = tf.reshape(input, [-1, 1])\n",
    "    k = np.float16(np.array([1.0, 1.0]).reshape([1,-1]))\n",
    "    output = tf.matmul(x, k)\n",
    "    output = tf.reshape(output,[-1, c, h, w * 2])\n",
    "    # m, c, w, h\n",
    "    xx = tf.transpose(output, [0, 1, 3, 2])\n",
    "    xx = tf.reshape(xx,[-1, 1])\n",
    "    output = tf.matmul(xx, k)\n",
    "    # m, c, w, h\n",
    "    output = tf.reshape(output, [-1, c, w * 2, h * 2])\n",
    "    output = tf.transpose(output, [0, 3, 2, 1])\n",
    "    outshape = tf.stack([m, h * 2, w * 2, c])\n",
    "    if mask != None:\n",
    "        dense_mask = tf.sparse_to_dense(mask, outshape, output, 0)\n",
    "        return output, dense_mask\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def semantic_seg_model(features, labels, mode):\n",
    "    \n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    \n",
    "    # Encoding starts here.\n",
    "\n",
    "    # Convolutional Layer 1\n",
    "    # Input: 100 x 100\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=features,\n",
    "      filters=10,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    # Convolutional Layer 2\n",
    "    # Input: 100 x 100\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs = conv1,\n",
    "        filters = 25,\n",
    "        kernel_size = [5, 5],\n",
    "        padding = \"same\",\n",
    "        activation = tf.nn.relu)\n",
    "    \n",
    "    # Convolutional Layer 3\n",
    "    # Input: 100 x 100\n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs = conv2,\n",
    "        filters = 50,\n",
    "        kernel_size = [5, 5],\n",
    "        padding = \"same\",\n",
    "        activation = tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer 1\n",
    "    # Input: 100 x 100\n",
    "    pool1 = tf.layers.max_pooling2d(inputs = conv3, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Convolutional Layer 4\n",
    "    # Input: 50 x 50\n",
    "    conv4 = tf.layers.conv2d(\n",
    "        inputs = pool1,\n",
    "        filters = 80,\n",
    "        kernel_size = [5, 5],\n",
    "        padding = \"same\",\n",
    "        activation = tf.nn.relu)\n",
    "    \n",
    "    # Decoding starts here.\n",
    "    \n",
    "    # Deconvolution Layer 4\n",
    "    # Input: 50 x 50\n",
    "    deconv4 = tf.layers.conv2d_transpose(\n",
    "        inputs = conv4,\n",
    "        filters = 50,\n",
    "        kernel_size = [5, 5],\n",
    "        padding = \"same\",\n",
    "        activation = tf.nn.relu)\n",
    "    \n",
    "    # Unpool Layer 1\n",
    "    # Input: 50 x 50\n",
    "    unpool1 = unpooling(deconv4, [tf.shape(features)[0], 50, 50, 50])\n",
    "    \n",
    "    # Deconvolution Layer 3\n",
    "    # Input: 100 x 100\n",
    "    deconv3 = tf.layers.conv2d_transpose(\n",
    "        inputs = unpool1,\n",
    "        filters = 25,\n",
    "        kernel_size = [5, 5],\n",
    "        padding = \"same\",\n",
    "        activation = tf.nn.relu)\n",
    "    \n",
    "    # Deconvolution Layer 2\n",
    "    # Input: 100 x 100\n",
    "    deconv2 = tf.layers.conv2d_transpose(\n",
    "        inputs = deconv3,\n",
    "        filters = 10,\n",
    "        kernel_size = [5, 5],\n",
    "        padding = \"same\",\n",
    "        activation = tf.nn.relu)\n",
    "    \n",
    "    deconv1 = tf.layers.conv2d_transpose(\n",
    "        inputs = deconv2,\n",
    "        filters = 3,\n",
    "        kernel_size = [5, 5],\n",
    "        padding = \"same\",\n",
    "        activation = tf.nn.relu)\n",
    "    \n",
    "    return deconv1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = get_input_img('0')\n",
    "\n",
    "height = 3900\n",
    "width = 6000\n",
    "channel = 3\n",
    "\n",
    "#image should be divided into patches as image size is very large\n",
    "batch_length_vertical = 39\n",
    "batch_length_horizontal = 60\n",
    "mini_batch = 1343\n",
    "\n",
    "#ksize_rows and ksize_cols will define the size of patches\n",
    "ksize_rows = 100\n",
    "ksize_cols = 100\n",
    "\n",
    "#patches will be overlapped by 25 pixels\n",
    "overlapping_region = 25\n",
    "\n",
    "\n",
    "tf_features = tf.placeholder(tf.float16, [None, int(height/batch_length_vertical), int(width/batch_length_horizontal), channel], name = 'features')\n",
    "tf_labels = tf.placeholder(tf.float16, [None, int(height/batch_length_vertical), int(width/batch_length_horizontal), channel], name = 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first make all the images with constant size\n",
    "features = np.pad(features, ((height - features.shape[0], 0), (width - features.shape[1], 0), (0,0)), mode = 'constant')\n",
    "labels = np.pad(labels, ((height - labels.shape[0], 0), (width - labels.shape[1], 0), (0,0)), mode = 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert 3-dims to 4-dims\n",
    "features = np.reshape(features, [-1, features.shape[0], features.shape[1], features.shape[2]])\n",
    "labels = np.reshape(labels, [-1, labels.shape[0], labels.shape[1], labels.shape[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract patches from image\n",
    "features = tf.extract_image_patches(features, ksizes = [1, ksize_rows, ksize_cols, 1], strides = [1, overlapping_region, overlapping_region, 1], padding = \"VALID\", rates = [1, 1, 1, 1])\n",
    "features = tf.reshape(features, [-1, ksize_rows, ksize_cols, channel])\n",
    "\n",
    "#extract patches from ground truth image\n",
    "labels = tf.extract_image_patches(labels, ksizes = [1, ksize_rows, ksize_cols, 1], strides = [1, overlapping_region, overlapping_region, 1], padding = \"VALID\", rates = [1, 1, 1, 1])\n",
    "labels = tf.reshape(labels, [-1, ksize_rows, ksize_cols, channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make mini-batch of image for training\n",
    "features = tf.reshape(features, [-1, int(features.shape.as_list()[0]/mini_batch), ksize_rows, ksize_cols, channel])\n",
    "labels = tf.reshape(labels, [-1, int(labels.shape.as_list()[0]/mini_batch), ksize_rows, ksize_cols,  channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = semantic_seg_model(tf_features, tf_labels, tf.estimator.ModeKeys.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(100), Dimension(100), Dimension(3)]),\n",
       " TensorShape([Dimension(None), Dimension(100), Dimension(100), Dimension(3)]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_features.shape, tf_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(1343), Dimension(27), Dimension(100), Dimension(100), Dimension(3)]),\n",
       " TensorShape([Dimension(1343), Dimension(27), Dimension(100), Dimension(100), Dimension(3)]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(100), Dimension(100), Dimension(3)])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs = 50\n",
    "\n",
    "# with tf.device(\"/gpu:0\"):\n",
    "\n",
    "#cost\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = output, labels = tf_labels)\n",
    "cost = tf.reduce_mean( cross_entropy )\n",
    "#     return cost, optimizer, accr\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "corr = tf.equal(tf.argmax(tf_labels,1), tf.argmax(output, 1))\n",
    "accr = tf.reduce_mean(tf.cast(corr, tf.float16))\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        train_loss = []; train_accuracy = []\n",
    "\n",
    "        for i in range(features.shape.as_list()[0]):\n",
    "#         for i in range(1):\n",
    "\n",
    "            batch_features, batch_labels = features[i], labels[i]\n",
    "\n",
    "            batch_features = np.reshape(batch_features.eval(session=sess), [-1, ksize_rows, ksize_cols, channel])\n",
    "            batch_labels = np.reshape(batch_labels.eval(session=sess), [-1, ksize_rows, ksize_cols, channel])\n",
    "            \n",
    "            feed_dict = {tf_features: batch_features, tf_labels: batch_labels}\n",
    "\n",
    "            _, sess_cost, sess_accuracy = sess.run([optimizer, cost, accr], feed_dict = feed_dict)\n",
    "            \n",
    "            train_loss.append(sess_cost)\n",
    "            train_accuracy.append(sess_accuracy)\n",
    "\n",
    "            # Average loss and accuracy\n",
    "        train_loss = np.mean(train_loss)\n",
    "        train_accuracy = np.mean(train_accuracy)\n",
    "\n",
    "        print (\"[%02d/%02d] trainLoss: %.4f trainAcc: %.2f\" \n",
    "               % (epoch + 1, epochs, train_loss, train_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
