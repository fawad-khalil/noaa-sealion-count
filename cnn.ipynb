{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fawad khalil\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blurred_img = cv2.GaussianBlur(labeled_img, (5,5), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_img(name):\n",
    "    labeled_img = cv.imread('D:/ML work/NOAA Sea Lion count/Data/Semantics Segmentation/' + name + '-processed.tif')\n",
    "    original_img = cv.imread('D:/ML work/NOAA Sea Lion count/Data/Train/' + name + '.jpg')\n",
    "    \n",
    "    return original_img, labeled_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/sjchoi86/Tensorflow-101/blob/master/notebooks/semseg_basic.ipynb\n",
    "def unpooling(inputOrg, size, mask=None):\n",
    "    # m, c, h, w order\n",
    "    m = size[0]\n",
    "    h = size[1]\n",
    "    w = size[2]\n",
    "    c = size[3]\n",
    "    input = tf.transpose(inputOrg, [0, 3, 1, 2])\n",
    "    x = tf.reshape(input, [-1, 1])\n",
    "    k = np.float16(np.array([1.0, 1.0]).reshape([1,-1]))\n",
    "    output = tf.matmul(x, k)\n",
    "    output = tf.reshape(output,[-1, c, h, w * 2])\n",
    "    # m, c, w, h\n",
    "    xx = tf.transpose(output, [0, 1, 3, 2])\n",
    "    xx = tf.reshape(xx,[-1, 1])\n",
    "    output = tf.matmul(xx, k)\n",
    "    # m, c, w, h\n",
    "    output = tf.reshape(output, [-1, c, w * 2, h * 2])\n",
    "    output = tf.transpose(output, [0, 3, 2, 1])\n",
    "    outshape = tf.stack([m, h * 2, w * 2, c])\n",
    "    if mask != None:\n",
    "        dense_mask = tf.sparse_to_dense(mask, outshape, output, 0)\n",
    "        return output, dense_mask\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(inputs, filters, kernel_size, strides = 1, padding = \"SAME\", bias_constant = 0.0, name = \"conv\"):\n",
    "    with tf.name_scope(name):\n",
    "#         return tf.layers.conv2d(inputs = inputs,\n",
    "#                                         filters = filters,\n",
    "#                                         kernel_size = kernel_size,\n",
    "#                                         padding = padding,\n",
    "#                                         strides = strides,\n",
    "#                                         use_bias = True,\n",
    "#                                         bias_initializer = tf.constant_initializer(bias_constant),\n",
    "#                                         activation = tf.nn.relu)\n",
    "        input_shape = inputs.shape.as_list()\n",
    "    \n",
    "        filter_tensor = tf.truncated_normal([kernel_size[0], kernel_size[1], input_shape[3], filters], dtype = tf.float16)\n",
    "        \n",
    "        filter = tf.Variable(initial_value = filter_tensor, name = \"kernel\")\n",
    "        bias = tf.Variable(tf.constant(bias_constant, shape=[filters]), name=\"bias\")\n",
    "        \n",
    "        conv2d = tf.nn.conv2d(input = inputs, filter = filter, strides = [1, strides, strides, 1], padding = padding)\n",
    "        \n",
    "        conv2d_32 = tf.cast(conv2d, dtype = tf.float32)\n",
    "        \n",
    "        activation = tf.nn.relu(conv2d_32 + bias)\n",
    "        \n",
    "        activation_16 = tf.cast(activation, dtype=tf.float16)\n",
    "        \n",
    "        tf.summary.histogram(\"weights\", filter)\n",
    "        tf.summary.histogram(\"biases\", bias)\n",
    "        tf.summary.histogram(\"activations\", activation)\n",
    "        \n",
    "        return activation_16\n",
    "    \n",
    "def max_pooling(input, kernel_size, strides, padding, name = \"max_pool\"):\n",
    "    with tf.name_scope(name):\n",
    "        return tf.nn.max_pooling(value = input, \n",
    "                                    ksize = [1, kernel_size[0], kernel_size[1], 1], \n",
    "                                    strides=[1, strides[0], strides[1], 1], \n",
    "                                    padding = padding)\n",
    "        \n",
    "#         w = tf.Variable(tf)\n",
    "\n",
    "def deconv_layer(inputs, filters, kernel_size, output_size, strides = 1, padding = \"SAME\", bias_constant = 0.0, name = \"deconv\"):\n",
    "    with tf.name_scope(name):\n",
    "#         return tf.layers.conv2d_transpose(inputs = inputs,\n",
    "#                                             filters = filters,\n",
    "#                                             kernel_size = kernel_size,\n",
    "#                                             strides = strides,\n",
    "#                                             padding = padding,\n",
    "#                                             use_bias = True,\n",
    "#                                             bias_initializer = tf.constant_initializer(bias_constant),\n",
    "#                                             activation = tf.nn.relu)\n",
    "\n",
    "        input_shape = inputs.shape.as_list()\n",
    "        deconv_shape = tf.stack([tf.shape(inputs)[0], output_size[0], output_size[1],filters])\n",
    "    \n",
    "        filter_tensor = tf.truncated_normal([kernel_size[0], kernel_size[1], filters, input_shape[3]], dtype = tf.float16)\n",
    "        \n",
    "        filter = tf.Variable(initial_value = filter_tensor, name = \"kernel\")\n",
    "        bias = tf.Variable(tf.constant(bias_constant, shape=[filters]), name=\"bias\")\n",
    "        \n",
    "        conv2d_transpose = tf.nn.conv2d_transpose(value = inputs, \n",
    "                                                  filter = filter, \n",
    "                                                  strides = [1, strides, strides, 1], \n",
    "                                                  output_shape=deconv_shape,\n",
    "                                                  padding = padding)\n",
    "        \n",
    "        conv2d_transpose_32 = tf.cast(conv2d_transpose, dtype = tf.float32)\n",
    "        \n",
    "        activation = tf.nn.relu(conv2d_transpose_32 + bias)\n",
    "        \n",
    "        activation_16 = tf.cast(activation, dtype=tf.float16)\n",
    "        \n",
    "        tf.summary.histogram(\"weights\", filter)\n",
    "        tf.summary.histogram(\"biases\", bias)\n",
    "        tf.summary.histogram(\"activations\", activation)\n",
    "        \n",
    "        return activation_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_seg_model(features, labels, mode):\n",
    "    \n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    \n",
    "    # Encoding starts here.\n",
    "\n",
    "    # Convolutional Layer 1\n",
    "    # Input: 100 x 100\n",
    "    conv1 = conv_layer(inputs=features,\n",
    "                        filters=10,\n",
    "                        kernel_size=[5, 5],\n",
    "                        bias_constant = 0.1,\n",
    "                        name = \"conv1\")\n",
    "    \n",
    "    print(conv1.shape)\n",
    "    \n",
    "    # Convolutional Layer 2\n",
    "    # Input: 100 x 100\n",
    "    conv2 = conv_layer(inputs = conv1,\n",
    "                        filters = 25,\n",
    "                        kernel_size = [5, 5],\n",
    "                        bias_constant = 0.1,\n",
    "                        name = \"conv2\")\n",
    "    print(conv2.shape)\n",
    "    # Convolutional Layer 3\n",
    "    # Input: 100 x 100\n",
    "    conv3 = conv_layer(inputs = conv2,\n",
    "                        filters = 50,\n",
    "                        kernel_size = [5, 5],\n",
    "                        bias_constant = 0.1,\n",
    "                        strides = 2,\n",
    "                        name = \"conv3\")\n",
    "    print(conv3.shape)\n",
    "    # Pooling Layer 1\n",
    "    # Input: 100 x 100\n",
    "#     pool1 = tf.layers.max_pooling2d(inputs = conv3, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Convolutional Layer 4\n",
    "    # Input: 50 x 50\n",
    "    conv4 = conv_layer(inputs = conv3,\n",
    "                        filters = 80,\n",
    "                        kernel_size = [5, 5],\n",
    "                        bias_constant = 0.1,\n",
    "                        strides = 2,\n",
    "                        name = \"conv4\")\n",
    "    print(conv4.shape)\n",
    "    # Decoding starts here.\n",
    "    \n",
    "    # Deconvolution Layer 4\n",
    "    # Input: 50 x 50\n",
    "    deconv4 = deconv_layer(inputs = conv4,\n",
    "                            filters = 50,\n",
    "                            kernel_size = [5, 5],\n",
    "                            bias_constant = 0.1,\n",
    "                            strides = 2,\n",
    "                            output_size = [50, 50],\n",
    "                            name = \"deconv4\")\n",
    "    print(deconv4)\n",
    "    # Unpool Layer 1\n",
    "    # Input: 50 x 50\n",
    "#     unpool1 = unpooling(deconv4, [tf.shape(features)[0], 50, 50, 50])\n",
    "    \n",
    "    # Deconvolution Layer 3\n",
    "    # Input: 100 x 100\n",
    "    deconv3 = deconv_layer(inputs = deconv4,\n",
    "                            filters = 25,\n",
    "                            kernel_size = [5, 5],\n",
    "                            bias_constant = 0.1,\n",
    "                            strides = 2,\n",
    "                            output_size = [100, 100],\n",
    "                            name = \"deconv3\")\n",
    "    print(deconv3)\n",
    "    # Deconvolution Layer 2\n",
    "    # Input: 100 x 100\n",
    "    deconv2 = deconv_layer(inputs = deconv3,\n",
    "                            filters = 10,\n",
    "                            kernel_size = [5, 5],\n",
    "                            bias_constant = 0.1,\n",
    "                            output_size = [100, 100],\n",
    "                            name = \"deconv2\")\n",
    "    print(deconv2)\n",
    "    deconv1 = deconv_layer(inputs = deconv2,\n",
    "                            filters = 3,\n",
    "                            kernel_size = [5, 5],\n",
    "                            output_size = [100, 100],\n",
    "                            bias_constant = 0.1,\n",
    "                            name = \"deconv1\")\n",
    "    \n",
    "    print(deconv1.shape)\n",
    "    return deconv1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = get_input_img('0')\n",
    "\n",
    "height = 3900\n",
    "width = 6000\n",
    "channel = 3\n",
    "\n",
    "#image should be divided into patches as image size is very large\n",
    "batch_length_vertical = 39\n",
    "batch_length_horizontal = 60\n",
    "mini_batch = 1343\n",
    "\n",
    "#ksize_rows and ksize_cols will define the size of patches\n",
    "ksize_rows = 100\n",
    "ksize_cols = 100\n",
    "\n",
    "#patches will be overlapped by 25 pixels\n",
    "overlapping_region = 25\n",
    "\n",
    "# Tensorflow placeholder\n",
    "tf_features = tf.placeholder(tf.float16, [None, int(height/batch_length_vertical), int(width/batch_length_horizontal), channel], name = 'features')\n",
    "tf_labels = tf.placeholder(tf.float16, [None, int(height/batch_length_vertical), int(width/batch_length_horizontal), channel], name = 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first make all the images with constant size\n",
    "features = np.pad(features, ((height - features.shape[0], 0), (width - features.shape[1], 0), (0,0)), mode = 'constant')\n",
    "labels = np.pad(labels, ((height - labels.shape[0], 0), (width - labels.shape[1], 0), (0,0)), mode = 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert 3-dims to 4-dims\n",
    "features = np.reshape(features, [-1, features.shape[0], features.shape[1], features.shape[2]])\n",
    "labels = np.reshape(labels, [-1, labels.shape[0], labels.shape[1], labels.shape[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract patches from image\n",
    "features = tf.extract_image_patches(features, ksizes = [1, ksize_rows, ksize_cols, 1], strides = [1, overlapping_region, overlapping_region, 1], padding = \"VALID\", rates = [1, 1, 1, 1])\n",
    "features = tf.reshape(features, [-1, ksize_rows, ksize_cols, channel])\n",
    "\n",
    "#extract patches from ground truth image\n",
    "labels = tf.extract_image_patches(labels, ksizes = [1, ksize_rows, ksize_cols, 1], strides = [1, overlapping_region, overlapping_region, 1], padding = \"VALID\", rates = [1, 1, 1, 1])\n",
    "labels = tf.reshape(labels, [-1, ksize_rows, ksize_cols, channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make mini-batch of image for training\n",
    "features = tf.reshape(features, [-1, int(features.shape.as_list()[0]/mini_batch), ksize_rows, ksize_cols, channel])\n",
    "labels = tf.reshape(labels, [-1, int(labels.shape.as_list()[0]/mini_batch), ksize_rows, ksize_cols,  channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 100, 100, 10)\n",
      "(?, 100, 100, 25)\n",
      "(?, 50, 50, 50)\n",
      "(?, 25, 25, 80)\n",
      "Tensor(\"deconv4/Cast_1:0\", shape=(?, 50, 50, 50), dtype=float16)\n",
      "Tensor(\"deconv3/Cast_1:0\", shape=(?, 100, 100, 25), dtype=float16)\n",
      "Tensor(\"deconv2/Cast_1:0\", shape=(?, 100, 100, 10), dtype=float16)\n",
      "(?, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "output = semantic_seg_model(tf_features, tf_labels, tf.estimator.ModeKeys.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv1_w = tf.get_variable(\"conv1/conv2d/kernel\")\n",
    "# conv2_w = tf.get_variable(\"conv2/kernel\")\n",
    "# conv3_w = tf.get_variable(\"conv3/kernel\")\n",
    "# conv4_w = tf.get_variable(\"conv4/kernel\")\n",
    "# deconv4_w = tf.get_variable(\"deconv4/kernel\")\n",
    "# deconv3_w = tf.get_variable(\"deconv3/kernel\")\n",
    "# deconv2_w = tf.get_variable(\"deconv2/kernel\")\n",
    "# deconv1_w = tf.get_variable(\"deconv1/kernel\")\n",
    "\n",
    "# conv1_b = tf.get_variable(\"conv1/bias\")\n",
    "# conv2_b = tf.get_variable(\"conv2/bias\")\n",
    "# conv3_b = tf.get_variable(\"conv3/bias\")\n",
    "# conv4_b = tf.get_variable(\"conv4/bias\")\n",
    "# deconv4_b = tf.get_variable(\"deconv4/bias\")\n",
    "# deconv3_b = tf.get_variable(\"deconv3/bias\")\n",
    "# deconv2_b = tf.get_variable(\"deconv2/bias\")\n",
    "# deconv1_b = tf.get_variable(\"deconv1/bias\")\n",
    "\n",
    "# conv1_act = tf.get_variable(\"conv1/activation\")\n",
    "# conv2_act = tf.get_variable(\"conv2/activation\")\n",
    "# conv3_act = tf.get_variable(\"conv3/activation\")\n",
    "# conv4_act = tf.get_variable(\"conv4/activation\")\n",
    "# deconv4_act = tf.get_variable(\"deconv4/activation\")\n",
    "# deconv3_act = tf.get_variable(\"deconv3/activation\")\n",
    "# deconv2_act = tf.get_variable(\"deconv2/activation\")\n",
    "# deconv1_act = tf.get_variable(\"deconv1/activation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_summeries(tensors, name):\n",
    "#     for tensor in tensors:\n",
    "#         tf.Summary.histogram(name, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_summeries([conv1_w, conv2_w, conv3_w, conv4_w, deconv4_w, deconv3_w, deconv2_w, deconv1_w], name = \"weights\")\n",
    "# add_summeries([conv1_b, conv2_b, conv3_b, conv4_b, deconv4_b, deconv3_b, deconv2_b, deconv1_b], name = \"biases\")\n",
    "# add_summeries([conv1_act, conv2_act, conv3_act, conv4_act, deconv4_act, deconv3_act, deconv2_act, deconv1_act], name = \"activations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(100), Dimension(100), Dimension(3)]),\n",
       " TensorShape([Dimension(None), Dimension(100), Dimension(100), Dimension(3)]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_features.shape, tf_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(1343), Dimension(27), Dimension(100), Dimension(100), Dimension(3)]),\n",
       " TensorShape([Dimension(1343), Dimension(27), Dimension(100), Dimension(100), Dimension(3)]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(100), Dimension(100), Dimension(3)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Tensorboard by executing this command in cmd: tensorboard --logdir C:\\Users\\Fawad Khalil\\AnacondaProjects\\sealion-count-kaggle-challenge\\semantic_seg_model_1\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "learning_rate=0.001\n",
    "\n",
    "# with tf.device(\"/gpu:0\"):\n",
    "\n",
    "#cost\n",
    "with tf.name_scope(\"cross_entropy\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = output, labels = tf_labels)\n",
    "    cost = tf.reduce_mean( cross_entropy )\n",
    "#     return cost, optimizer, accr\n",
    "    tf.summary.scalar(\"xent\", cost)\n",
    "\n",
    "#optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(tf_labels,1), tf.argmax(output, 1))\n",
    "    accr = tf.reduce_mean(tf.cast(correct_prediction, tf.float16))\n",
    "    tf.summary.scalar(\"accuracy\", accr)\n",
    "    \n",
    "summ = tf.summary.merge_all()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "log_file = \"semantic_seg_model_1\"\n",
    "\n",
    "writer = tf.summary.FileWriter(\"./\" + log_file)\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "print(\"Start Tensorboard by executing this command in cmd: tensorboard --logdir \" + os.getcwd() + \"\\\\\" + log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv1/kernel:0' shape=(5, 5, 3, 10) dtype=float16_ref>,\n",
       " <tf.Variable 'conv1/bias:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2/kernel:0' shape=(5, 5, 10, 25) dtype=float16_ref>,\n",
       " <tf.Variable 'conv2/bias:0' shape=(25,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv3/kernel:0' shape=(5, 5, 25, 50) dtype=float16_ref>,\n",
       " <tf.Variable 'conv3/bias:0' shape=(50,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv4/kernel:0' shape=(5, 5, 50, 80) dtype=float16_ref>,\n",
       " <tf.Variable 'conv4/bias:0' shape=(80,) dtype=float32_ref>,\n",
       " <tf.Variable 'deconv4/kernel:0' shape=(5, 5, 50, 80) dtype=float16_ref>,\n",
       " <tf.Variable 'deconv4/bias:0' shape=(50,) dtype=float32_ref>,\n",
       " <tf.Variable 'deconv3/kernel:0' shape=(5, 5, 25, 50) dtype=float16_ref>,\n",
       " <tf.Variable 'deconv3/bias:0' shape=(25,) dtype=float32_ref>,\n",
       " <tf.Variable 'deconv2/kernel:0' shape=(5, 5, 10, 25) dtype=float16_ref>,\n",
       " <tf.Variable 'deconv2/bias:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'deconv1/kernel:0' shape=(5, 5, 3, 10) dtype=float16_ref>,\n",
       " <tf.Variable 'deconv1/bias:0' shape=(3,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2017-12-29 15:46:42.942306\n"
     ]
    }
   ],
   "source": [
    "print(\"Start time: \" + str(datetime.datetime.now()))\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    train_loss = []; train_accuracy = []\n",
    "\n",
    "    for i in range(features.shape.as_list()[0]):\n",
    "#         for i in range(1):\n",
    "\n",
    "        batch_features, batch_labels = features[i], labels[i]\n",
    "\n",
    "        batch_features = np.reshape(batch_features.eval(session=sess), [-1, ksize_rows, ksize_cols, channel])\n",
    "        batch_labels = np.reshape(batch_labels.eval(session=sess), [-1, ksize_rows, ksize_cols, channel])\n",
    "\n",
    "        feed_dict = {tf_features: batch_features, tf_labels: batch_labels}\n",
    "\n",
    "        _, sess_cost, sess_accuracy = sess.run([optimizer, cost, accr], feed_dict = feed_dict)\n",
    "\n",
    "        train_loss.append(sess_cost)\n",
    "        train_accuracy.append(sess_accuracy)\n",
    "\n",
    "        # Average loss and accuracy\n",
    "    train_loss = np.mean(train_loss)\n",
    "    train_accuracy = np.mean(train_accuracy)\n",
    "\n",
    "    print (\"[%02d/%02d] trainLoss: %.4f trainAcc: %.2f\" \n",
    "           % (epoch + 1, epochs, train_loss, train_accuracy))\n",
    "\n",
    "sess.close()\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "print(\"Start Time: \" + str(start_time))\n",
    "print(\"End Time: \" + str(end_time))\n",
    "print(\"Time Taken: \" + end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
